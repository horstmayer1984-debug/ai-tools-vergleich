---
title: "Was Anthropic über KI-Agenten herausgefunden hat: Die wichtigsten Erkenntnisse"
date: "2026-02-18"
draft: false
categories: [news, research, ai, agents]
tags: [ai-agents, autonomy, anthropic, claude-code, llm]
image: "vergleiche/anthropic-agent-autonomie-forschung/hero.jpg"
seo_score: 90
word_count: 580
meta_desc: "Anthropic hat Millionen Interaktionen analysiert. Das zeigt: KI-Agenten werden immer autonomer. Die Zahlen überraschen."
---

# Was Anthropic über KI-Agenten herausgefunden hat: Die wichtigsten Erkenntnisse

**Das Wichtigste zuerst:** KI-Agenten arbeiten immer länger ohne menschliche Hilfe. Bei Claude Code hat sich die längste ununterbrochene Arbeitszeit fast verdoppelt. Von unter 25 Minuten auf über 45 Minuten in nur drei Monaten. Das zeigt eine neue Studie von Anthropic.

---

## Was die Studie untersucht

Anthropic hat Millionen von Mensch-Maschine-Interaktionen analysiert. Das ist neu daran:

Es geht nicht um Benchmarks oder künstliche Tests. Es geht um echte Nutzung. Wie lange lassen Menschen einen KI-Agenten tatsächlich arbeiten? Wann greifen sie ein? Und wie verändert sich das mit der Erfahrung?

Die Analyse basiert auf zwei Quellen:
1. **Claude Code** (der eigene Coding-Assistent) für detaillierte Einblicke
2. **Public API** für breite Daten über verschiedene Einsatzbereiche

---

## Die zentralen Ergebnisse

### 1. Agenten werden autonomer

Die Zahl, die springt: Die längsten Arbeitssitzungen bei Claude Code dauern jetzt über 45 Minuten. Vor drei Monaten waren es unter 25 Minuten.

Das Besondere: Der Anstieg passiert kontinuierlich. Nicht nur, wenn ein neues Modell herauskommt. Das bedeutet, bestehende Modelle können mehr, als Nutzer ihnen zutrauen. Es gibt eine Lücke zwischen Fähigkeit und tatsächlicher Nutzung.

Bei Anthropic intern ist das noch extremer. Der Erfolg bei schwierigen Aufgaben hat sich verdoppelt. Gleichzeitig sind die menschlichen Eingriffe pro Sitzung von 5,4 auf 3,3 gesunken.

### 2. Erfahrene Nutzer vertrauen mehr – und greifen trotzdem mehr ein

Mit der Zeit ändern Menschen ihr Verhalten. Neulinge (unter 50 Sitzungen) nutzen die Auto-approve-Funktion zu etwa 20 Prozent. Nach 750 Sitzungen sind es über 40 Prozent.

Das Interessante: Erfahrene Nutzer greifen zwar mehr Auto-approve zu, aber sie unterbrechen auch öfter. Bei Neulingen liegt die Unterbrechungsrate bei 5 Prozent der Arbeitsschritte. Bei Erfahrenen bei 9 Prozent.

Warum? Wer das Tool kennt, lässt es laufen. Aber er achtet genauer darauf, wann tatsächlich eingegriffen werden muss. Das ist aktives Vertrauen, nicht Passivität.

### 3. Agenten fragen öfter nach als Menschen eingreifen

Bei den komplexesten Aufgaben stoppt Claude Code, um nachzufragen. Und zwar mehr als doppelt so oft, wie Menschen von sich aus eingreifen würden.

Das ist ein Sicherheitsfeature. Der Agent fragt, bevor er etwas macht, statt hinterher zu korrigieren. Manchmal kostet das Zeit, aber es verhindert Fehler.

### 4. Risiko: Noch gering, aber in sensiblen Bereichen

Die gute Nachricht: Die meisten Agenten-Aktionen sind niedrigrisiko und umkehrbar. Software-Entwicklung macht fast 50 Prozent aller Agenten.

Aber es gibt-Nutzung aus Wachstum in sensiblen Bereichen: Healthcare, Finance, Cybersecurity. Noch nicht in großem Maßstab, aber die Richtung ist erkennbar.

---

## Was das für dich bedeutet

Wenn du KI-Agenten nutzt, passiert etwas Typisches: Am Anfang bestätigst du jeden Schritt. Mit der Zeit lässt du mehr laufen. Und irgendwann hast du ein Gespür dafür, wann du eingreifen musst.

Die Studie zeigt aber auch: Die Werkzeuge können mehr, als wir ihnen zutrauen. Die Lücke zwischen Fähigkeit und Nutzung ist groß.

**Konkreter Tipp:** Teste die Auto-approve-Funktion bei wiederkehrenden Aufgaben. Du wirst überrascht sein, wie viel der Agent allein kann.

---

## Fazit

Die Anthropic-Daten zeigen: KI-Agenten sind auf dem Weg in die Autonomie. Langsam, aber stetig. Die größte Erkenntnis: Wir unterschätzen, was die Modelle bereits können. Das wird sich ändern, wenn wir mehr Vertrauen aufbauen.

**Stand Februar 2026:** Agenten sind noch nicht perfekt. Aber sie werden besser. Und wir lernen gerade, wie wir mit ihnen zusammenarbeiten.

---

*Quelle: [Anthropic Research – Measuring Agent Autonomy](https://www.anthropic.com/research/measuring-agent-autonomy)*
